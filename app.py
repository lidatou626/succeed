import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from surprise import Dataset, Reader, SVD
import jieba
from snownlp import SnowNLP
import os
import time
from datetime import datetime
import pickle
import plotly.express as px
import plotly.graph_objects as go
from PIL import Image

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="5Açº§æ™¯åŒºæ¨èç³»ç»Ÿ",
    page_icon="ğŸï¸",
    layout="wide"
)

# è‡ªå®šä¹‰CSSæ ·å¼ï¼ˆå¢å¼ºç‰ˆï¼‰
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem !important;
        color: #1e88e5;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.8rem !important;
        color: #388e3c;
        margin-top: 1.5rem;
        margin-bottom: 0.5rem;
    }
    .scenic-title {
        font-size: 1.5rem !important;
        font-weight: bold;
        color: #263238;
        margin-bottom: 0.5rem;
    }
    .card {
        background-color: #f8f9fa;
        border-radius: 12px;
        padding: 1.2rem;
        margin-bottom: 1.5rem;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        transition: transform 0.3s, box-shadow 0.3s;
    }
    .card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }
    .scenic-image {
        width: 100%;
        border-radius: 8px;
        margin-bottom: 1rem;
        box-shadow: 0 4px 10px rgba(0,0,0,0.1);
    }
    .dataframe {
        border-radius: 5px;
        overflow: hidden;
    }
    .stButton>button {
        background-color: #1e88e5;
        color: white;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        font-weight: bold;
    }
    .stSelectbox select {
        background-color: #f0f2f6;
        border-radius: 5px;
    }
    .stTextInput input {
        border-radius: 5px;
    }
    .stRadio div {
        padding: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ç¼“å­˜æ•°æ®åŠ è½½å‡½æ•°ï¼ˆå¢åŠ å›¾ç‰‡è·¯å¾„åŠ è½½ï¼‰
@st.cache_data
def load_data():
    try:
        # å°è¯•åŠ è½½é¢„å¤„ç†åçš„æ•°æ®
        df = pd.read_excel('æ™¯åŒºä¸è¯„è®ºæ•°æ®é›†.xlsx_å…³é”®è¯ä¸æƒ…æ„Ÿå¾—åˆ†.xlsx')
        
        # å‡è®¾æ•°æ®é›†ä¸­åŒ…å«å›¾ç‰‡è·¯å¾„åˆ—"å›¾ç‰‡è·¯å¾„"ï¼Œå¦‚æœæ²¡æœ‰è¯·ä¿®æ”¹æ­¤å¤„
        if 'å›¾ç‰‡è·¯å¾„' in df.columns:
            # æ„å»ºæ™¯åŒºåç§°åˆ°å›¾ç‰‡è·¯å¾„çš„æ˜ å°„
            scenic_image_map = df[['æ™¯åŒºåç§°', 'å›¾ç‰‡è·¯å¾„']].drop_duplicates().set_index('æ™¯åŒºåç§°')['å›¾ç‰‡è·¯å¾„'].to_dict()
        else:
            # å¦‚æœæ²¡æœ‰å›¾ç‰‡è·¯å¾„ï¼Œåˆ›å»ºç©ºæ˜ å°„
            scenic_image_map = {}
            st.warning("æ•°æ®é›†ä¸­æœªæ‰¾åˆ°å›¾ç‰‡è·¯å¾„ä¿¡æ¯ï¼Œè¯·ç¡®ä¿æ•°æ®åŒ…å«'å›¾ç‰‡è·¯å¾„'åˆ—")
        
        scenic_reviews = df.groupby('æ™¯åŒºåç§°')['è¯„è®ºå†…å®¹'].agg(lambda x: ' '.join(x)).reset_index()
        
        # è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
        vectorizer = TfidfVectorizer(stop_words=None)
        tfidf_matrix = vectorizer.fit_transform(scenic_reviews['è¯„è®ºå†…å®¹'])
        text_similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)
        scenic_index = {name: i for i, name in enumerate(scenic_reviews['æ™¯åŒºåç§°'])}
        
        # åŠ è½½å›¾ç‰‡ç›¸ä¼¼åº¦
        if os.path.exists('scenic_similarity.npy'):
            image_similarity_matrix = np.load('scenic_similarity.npy')
        else:
            image_similarity_matrix = None
            
        # åŠ è½½SVDæ¨¡å‹
        if os.path.exists('svd_model.pkl'):
            with open('svd_model.pkl', 'rb') as f:
                svd_model = pickle.load(f)
        else:
            # å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œåˆ™è®­ç»ƒä¸€ä¸ªæ–°æ¨¡å‹
            reader = Reader(rating_scale=(1, 5))
            data = Dataset.load_from_df(df[['ç”¨æˆ·ID', 'æ™¯åŒºåç§°', 'è¯„åˆ†']], reader)
            trainset = data.build_full_trainset()
            svd_model = SVD(n_factors=100, n_epochs=20, random_state=42)
            svd_model.fit(trainset)
            with open('svd_model.pkl', 'wb') as f:
                pickle.dump(svd_model, f)
        
        return df, scenic_reviews, text_similarity_matrix, image_similarity_matrix, scenic_index, svd_model, scenic_image_map
    
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½é”™è¯¯: {str(e)}")
        return None, None, None, None, None, None, {}

# æ˜¾ç¤ºæ™¯åŒºå›¾ç‰‡çš„å‡½æ•°
def display_scenic_image(scenic_name, image_map, default_image="default_scenic.jpg"):
    """æ˜¾ç¤ºæ™¯åŒºå›¾ç‰‡ï¼Œæ”¯æŒè‡ªå®šä¹‰é»˜è®¤å›¾ç‰‡"""
    if scenic_name in image_map and os.path.exists(image_map[scenic_name]):
        try:
            return st.image(image_map[scenic_name], caption=scenic_name, use_column_width=True, output_format="PNG")
        except Exception as e:
            st.warning(f"åŠ è½½å›¾ç‰‡ {image_map[scenic_name]} æ—¶å‡ºé”™: {str(e)}")
            return st.image(default_image, caption="é»˜è®¤æ™¯åŒºå›¾ç‰‡", use_column_width=True, output_format="PNG")
    else:
        st.warning(f"æœªæ‰¾åˆ° {scenic_name} çš„å›¾ç‰‡ï¼Œæ˜¾ç¤ºé»˜è®¤å›¾ç‰‡")
        return st.image(default_image, caption="é»˜è®¤æ™¯åŒºå›¾ç‰‡", use_column_width=True, output_format="PNG")

# ä¸»åº”ç”¨ç¨‹åº
def main():
    # é¡µé¢æ ‡é¢˜
    st.markdown("<h1 class='main-header'>5Açº§æ™¯åŒºæ¨èç³»ç»Ÿ</h1>", unsafe_allow_html=True)
    st.markdown("---")
    
    # åŠ è½½æ•°æ®ï¼ˆåŒ…å«å›¾ç‰‡æ˜ å°„ï¼‰
    with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
        df, scenic_reviews, text_similarity_matrix, image_similarity_matrix, scenic_index, svd_model, scenic_image_map = load_data()
    
    if df is None:
        st.warning("æ— æ³•åŠ è½½æ•°æ®ï¼Œè¯·ç¡®ä¿ç›¸å…³æ–‡ä»¶å­˜åœ¨ã€‚")
        return
    
    # ä¾§è¾¹æ 
    st.sidebar.header("å¯¼èˆª")
    page = st.sidebar.radio(
        "é€‰æ‹©åŠŸèƒ½",
        ["æ™¯åŒºæ¦‚è§ˆ", "æƒ…æ„Ÿåˆ†æ", "ç›¸ä¼¼æ™¯åŒºæ¨è", "ä¸ªæ€§åŒ–æ¨è"]
    )
    
    # æ™¯åŒºæ¦‚è§ˆé¡µé¢
    if page == "æ™¯åŒºæ¦‚è§ˆ":
        st.markdown("<h2 class='sub-header'>æ™¯åŒºæ•°æ®æ¦‚è§ˆ</h2>", unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### æ™¯åŒºåŸºæœ¬ä¿¡æ¯")
            # å±•ç¤ºæ™¯åŒºæ•°é‡ã€è¯„è®ºæ•°é‡ç­‰åŸºæœ¬ä¿¡æ¯
            total_scenics = df['æ™¯åŒºåç§°'].nunique()
            total_comments = len(df)
            total_users = df['ç”¨æˆ·ID'].nunique()
            avg_rating = df['è¯„åˆ†'].mean()
            
            st.metric("æ™¯åŒºæ€»æ•°", total_scenics)
            st.metric("è¯„è®ºæ€»æ•°", total_comments)
            st.metric("ç”¨æˆ·æ€»æ•°", total_users)
            st.metric("å¹³å‡è¯„åˆ†", f"{avg_rating:.2f}/5.0")
            
            # è¯„åˆ†åˆ†å¸ƒ
            st.markdown("#### è¯„åˆ†åˆ†å¸ƒ")
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.countplot(x='è¯„åˆ†', data=df, ax=ax)
            ax.set_title('æ™¯åŒºè¯„åˆ†åˆ†å¸ƒ')
            st.pyplot(fig)
        
        with col2:
            st.markdown("#### çƒ­é—¨æ™¯åŒºTOP10")
            # æŒ‰è¯„è®ºæ•°ç»Ÿè®¡çƒ­é—¨æ™¯åŒº
            top_scenics = df.groupby('æ™¯åŒºåç§°').size().sort_values(ascending=False).head(10)
            
            fig = px.bar(
                x=top_scenics.index,
                y=top_scenics.values,
                labels={'x': 'æ™¯åŒºåç§°', 'y': 'è¯„è®ºæ•°é‡'},
                title='è¯„è®ºæ•°é‡æœ€å¤šçš„æ™¯åŒº'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig)
            
            # å¹³å‡è¯„åˆ†æœ€é«˜çš„æ™¯åŒº
            st.markdown("#### è¯„åˆ†æœ€é«˜çš„æ™¯åŒºTOP10")
            high_rated = df.groupby('æ™¯åŒºåç§°')['è¯„åˆ†'].mean().sort_values(ascending=False).head(10)
            
            fig = px.bar(
                x=high_rated.index,
                y=high_rated.values,
                labels={'x': 'æ™¯åŒºåç§°', 'y': 'å¹³å‡è¯„åˆ†'},
                title='å¹³å‡è¯„åˆ†æœ€é«˜çš„æ™¯åŒº'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig)
        
        # æ™¯åŒºè¯¦ç»†ä¿¡æ¯è¡¨æ ¼ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«å›¾ç‰‡é¢„è§ˆï¼‰
        st.markdown("#### æ™¯åŒºè¯¦ç»†ä¿¡æ¯ï¼ˆå«å›¾ç‰‡é¢„è§ˆï¼‰")
        scenic_info = df[['æ™¯åŒºåç§°', 'è¯„åˆ†', 'æƒ…æ„Ÿå¾—åˆ†']].drop_duplicates()
        
        # åˆ›å»ºåŒ…å«å›¾ç‰‡çš„è¡¨æ ¼
        for _, row in scenic_info.iterrows():
            scenic_name = row['æ™¯åŒºåç§°']
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1:
                st.markdown(f"<h3 class='scenic-title'>{scenic_name}</h3>", unsafe_allow_html=True)
                display_scenic_image(scenic_name, scenic_image_map)
            with col2:
                st.metric("è¯„åˆ†", f"{row['è¯„åˆ†']:.2f}/5.0")
            with col3:
                st.metric("æƒ…æ„Ÿå¾—åˆ†", f"{row['æƒ…æ„Ÿå¾—åˆ†']:.4f}")
            st.markdown("---")
    
    # æƒ…æ„Ÿåˆ†æé¡µé¢
    elif page == "æƒ…æ„Ÿåˆ†æ":
        st.markdown("<h2 class='sub-header'>æ™¯åŒºè¯„è®ºæƒ…æ„Ÿåˆ†æ</h2>", unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ")
            # æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.histplot(df['æƒ…æ„Ÿå¾—åˆ†'].dropna(), kde=True, ax=ax)
            ax.set_title('è¯„è®ºæƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ')
            ax.set_xlabel('æƒ…æ„Ÿå¾—åˆ† (0=è´Ÿé¢, 1=æ­£é¢)')
            st.pyplot(fig)
            
            # æƒ…æ„Ÿå¾—åˆ†ä¸è¯„åˆ†çš„å…³ç³»
            st.markdown("#### æƒ…æ„Ÿå¾—åˆ†ä¸è¯„åˆ†çš„å…³ç³»")
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.scatterplot(x='è¯„åˆ†', y='æƒ…æ„Ÿå¾—åˆ†', data=df, ax=ax)
            ax.set_title('æƒ…æ„Ÿå¾—åˆ†ä¸è¯„åˆ†çš„å…³ç³»')
            st.pyplot(fig)
        
        with col2:
            st.markdown("#### æƒ…æ„Ÿå¾—åˆ†æœ€é«˜çš„æ™¯åŒº")
            # æŒ‰æƒ…æ„Ÿå¾—åˆ†æ’åºçš„æ™¯åŒº
            sentiment_by_scenic = df.groupby('æ™¯åŒºåç§°')['æƒ…æ„Ÿå¾—åˆ†'].mean().sort_values(ascending=False)
            
            fig = px.bar(
                x=sentiment_by_scenic.index[:10],
                y=sentiment_by_scenic.values[:10],
                labels={'x': 'æ™¯åŒºåç§°', 'y': 'å¹³å‡æƒ…æ„Ÿå¾—åˆ†'},
                title='æƒ…æ„Ÿå¾—åˆ†æœ€é«˜çš„æ™¯åŒºTOP10'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig)
            
            # æƒ…æ„Ÿå¾—åˆ†æœ€ä½çš„æ™¯åŒº
            st.markdown("#### æƒ…æ„Ÿå¾—åˆ†æœ€ä½çš„æ™¯åŒº")
            fig = px.bar(
                x=sentiment_by_scenic.index[-10:],
                y=sentiment_by_scenic.values[-10:],
                labels={'x': 'æ™¯åŒºåç§°', 'y': 'å¹³å‡æƒ…æ„Ÿå¾—åˆ†'},
                title='æƒ…æ„Ÿå¾—åˆ†æœ€ä½çš„æ™¯åŒºTOP10'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig)
        
        # å…³é”®è¯åˆ†æ
        st.markdown("#### æ™¯åŒºè¯„è®ºå…³é”®è¯åˆ†æ")
        selected_scenic = st.selectbox("é€‰æ‹©æ™¯åŒºæŸ¥çœ‹å…³é”®è¯", df['æ™¯åŒºåç§°'].unique())
        
        if selected_scenic:
            # è·å–è¯¥æ™¯åŒºçš„è¯„è®º
            scenic_comments = df[df['æ™¯åŒºåç§°'] == selected_scenic]['è¯„è®ºå†…å®¹'].dropna()
            
            # æå–å…³é”®è¯
            all_keywords = []
            for comment in scenic_comments:
                words = jieba.lcut(comment)
                all_keywords.extend(words)
            
            # ç»Ÿè®¡è¯é¢‘
            from collections import Counter
            word_counts = Counter(all_keywords)
            top_keywords = word_counts.most_common(20)
            
            # è¿‡æ»¤æ‰å•ä¸ªå­—ç¬¦å’Œåœç”¨è¯
            filtered_keywords = [(word, count) for word, count in top_keywords if len(word) > 1]
            
            if filtered_keywords:
                fig = px.bar(
                    x=[word for word, _ in filtered_keywords],
                    y=[count for _, count in filtered_keywords],
                    labels={'x': 'å…³é”®è¯', 'y': 'å‡ºç°æ¬¡æ•°'},
                    title=f'{selected_scenic} è¯„è®ºä¸­å‡ºç°é¢‘ç‡æœ€é«˜çš„å…³é”®è¯'
                )
                st.plotly_chart(fig)
                
                # æ˜¾ç¤ºæ™¯åŒºå›¾ç‰‡
                st.markdown(f"<h3 class='scenic-title'>{selected_scenic} å›¾ç‰‡</h3>", unsafe_allow_html=True)
                display_scenic_image(selected_scenic, scenic_image_map)
            else:
                st.info("è¯¥æ™¯åŒºè¯„è®ºä¸­æ²¡æœ‰è¶³å¤Ÿçš„å…³é”®è¯ä¿¡æ¯")
    
    # ç›¸ä¼¼æ™¯åŒºæ¨èé¡µé¢ï¼ˆå…³é”®ä¿®æ”¹ç‚¹ï¼šæ·»åŠ å›¾ç‰‡ï¼‰
    elif page == "ç›¸ä¼¼æ™¯åŒºæ¨è":
        st.markdown("<h2 class='sub-header'>ç›¸ä¼¼æ™¯åŒºæ¨è</h2>", unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### é€‰æ‹©æ™¯åŒºæŸ¥çœ‹ç›¸ä¼¼æ¨è")
            selected_scenic = st.selectbox("é€‰æ‹©æ™¯åŒº", df['æ™¯åŒºåç§°'].unique())
            
            if selected_scenic and selected_scenic in scenic_index:
                idx = scenic_index[selected_scenic]
                
                # è®¡ç®—ç»¼åˆç›¸ä¼¼åº¦ï¼ˆæ–‡æœ¬+å›¾åƒï¼‰
                if text_similarity_matrix is not None and image_similarity_matrix is not None:
                    # æƒé‡å¯ä»¥è°ƒæ•´
                    text_weight, image_weight = 0.6, 0.4
                    combined_similarity = (text_weight * text_similarity_matrix) + (image_weight * image_similarity_matrix)
                else:
                    combined_similarity = text_similarity_matrix
                
                # è·å–ç›¸ä¼¼åº¦å¾—åˆ†
                sim_scores = list(enumerate(combined_similarity[idx]))
                sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
                
                # è·å–TOP5ç›¸ä¼¼æ™¯åŒº
                top_scenics = sim_scores[1:6]  # æ’é™¤è‡ªèº«
                
                st.markdown(f"### ä¸ {selected_scenic} æœ€ç›¸ä¼¼çš„æ™¯åŒº")
                
                # æ˜¾ç¤ºé€‰ä¸­æ™¯åŒºçš„å›¾ç‰‡
                st.markdown(f"<h3 class='scenic-title'>{selected_scenic} å›¾ç‰‡</h3>", unsafe_allow_html=True)
                display_scenic_image(selected_scenic, scenic_image_map)
                
                for i, (scenic_idx, score) in enumerate(top_scenics):
                    similar_scenic = scenic_reviews.iloc[scenic_idx]['æ™¯åŒºåç§°']
                    avg_rating = df[df['æ™¯åŒºåç§°'] == similar_scenic]['è¯„åˆ†'].mean()
                    avg_sentiment = df[df['æ™¯åŒºåç§°'] == similar_scenic]['æƒ…æ„Ÿå¾—åˆ†'].mean()
                    
                    st.markdown(f"""
                    <div class="card">
                        <h3 class='scenic-title'>{i+1}. {similar_scenic}</h3>
                        <p>ç›¸ä¼¼åº¦: {score:.4f}</p>
                        <p>å¹³å‡è¯„åˆ†: {avg_rating:.2f}/5.0</p>
                        <p>æƒ…æ„Ÿå¾—åˆ†: {avg_sentiment:.4f}</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # åœ¨æ¯ä¸ªç›¸ä¼¼æ™¯åŒºå¡ç‰‡ä¸­æ·»åŠ å›¾ç‰‡
                    display_scenic_image(similar_scenic, scenic_image_map)
            else:
                st.warning("è¯¥æ™¯åŒºä¸åœ¨æ•°æ®é›†ä¸­æˆ–æ— æ³•è®¡ç®—ç›¸ä¼¼åº¦")
        
        with col2:
            st.markdown("#### æ™¯åŒºç›¸ä¼¼åº¦çƒ­åŠ›å›¾")
            
            if text_similarity_matrix is not None:
                # é€‰æ‹©TOP20çƒ­é—¨æ™¯åŒºæ˜¾ç¤ºçƒ­åŠ›å›¾
                top_scenic_names = df.groupby('æ™¯åŒºåç§°').size().sort_values(ascending=False).head(20).index
                top_indices = [scenic_index[name] for name in top_scenic_names if name in scenic_index]
                
                if top_indices:
                    # æˆªå–è¿™äº›æ™¯åŒºçš„ç›¸ä¼¼åº¦çŸ©é˜µ
                    sub_matrix = text_similarity_matrix[np.ix_(top_indices, top_indices)]
                    
                    fig = px.imshow(
                        sub_matrix,
                        labels=dict(x="æ™¯åŒº", y="æ™¯åŒº", color="ç›¸ä¼¼åº¦"),
                        x=top_scenic_names,
                        y=top_scenic_names
                    )
                    fig.update_layout(height=800)
                    st.plotly_chart(fig)
                    
                    # æ˜¾ç¤ºçƒ­é—¨æ™¯åŒºå›¾ç‰‡é¢„è§ˆ
                    st.markdown("#### çƒ­é—¨æ™¯åŒºå›¾ç‰‡é¢„è§ˆ")
                    for name in top_scenic_names[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                        if name in scenic_image_map and os.path.exists(scenic_image_map[name]):
                            col1, col2 = st.columns([4, 1])
                            with col1:
                                st.markdown(f"<h4>{name}</h4>", unsafe_allow_html=True)
                            with col2:
                                st.image(scenic_image_map[name], width=100)
                else:
                    st.info("æ²¡æœ‰è¶³å¤Ÿçš„æ™¯åŒºæ•°æ®æ¥ç”Ÿæˆçƒ­åŠ›å›¾")
            else:
                st.warning("æ— æ³•åŠ è½½ç›¸ä¼¼åº¦æ•°æ®")
    
    # ä¸ªæ€§åŒ–æ¨èé¡µé¢ï¼ˆå…³é”®ä¿®æ”¹ç‚¹ï¼šæ·»åŠ å›¾ç‰‡ï¼‰
    elif page == "ä¸ªæ€§åŒ–æ¨è":
        st.markdown("<h2 class='sub-header'>ä¸ªæ€§åŒ–æ™¯åŒºæ¨è</h2>", unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ä¸ºç”¨æˆ·æ¨èæ™¯åŒº")
            user_id = st.number_input("è¾“å…¥ç”¨æˆ·ID", min_value=int(df['ç”¨æˆ·ID'].min()), max_value=int(df['ç”¨æˆ·ID'].max()), value=25)
            
            if user_id:
                # è·å–ç”¨æˆ·å»è¿‡çš„æ™¯åŒº
                visited_scenics = df[df['ç”¨æˆ·ID'] == user_id]['æ™¯åŒºåç§°'].unique()
                
                if len(visited_scenics) == 0:
                    st.warning(f"ç”¨æˆ· {user_id} æ²¡æœ‰å»è¿‡ä»»ä½•æ™¯åŒºï¼Œæ— æ³•æä¾›ä¸ªæ€§åŒ–æ¨è")
                else:
                    st.markdown(f"#### ç”¨æˆ· {user_id} å»è¿‡çš„æ™¯åŒº")
                    visited_info = df[df['ç”¨æˆ·ID'] == user_id][['æ™¯åŒºåç§°', 'è¯„åˆ†', 'æƒ…æ„Ÿå¾—åˆ†']].drop_duplicates()
                    
                    # æ˜¾ç¤ºç”¨æˆ·å»è¿‡çš„æ™¯åŒºå›¾ç‰‡
                    for scenic in visited_scenics:
                        st.markdown(f"<h3 class='scenic-title'>{scenic}</h3>", unsafe_allow_html=True)
                        display_scenic_image(scenic, scenic_image_map)
                        st.metric("è¯„åˆ†", f"{df[df['æ™¯åŒºåç§°'] == scenic]['è¯„åˆ†'].mean():.2f}/5.0")
                        st.metric("æƒ…æ„Ÿå¾—åˆ†", f"{df[df['æ™¯åŒºåç§°'] == scenic]['æƒ…æ„Ÿå¾—åˆ†'].mean():.4f}")
                        st.markdown("---")
                    
                    # æ¨èç›¸ä¼¼æ™¯åŒº
                    similar_scenics = []
                    for scenic_name in visited_scenics:
                        if scenic_name not in scenic_index:
                            continue
                            
                        idx = scenic_index[scenic_name]
                        
                        # è®¡ç®—ç»¼åˆç›¸ä¼¼åº¦
                        if text_similarity_matrix is not None and image_similarity_matrix is not None:
                            text_weight, image_weight = 0.6, 0.4
                            combined_similarity = (text_weight * text_similarity_matrix) + (image_weight * image_similarity_matrix)
                        else:
                            combined_similarity = text_similarity_matrix
                            
                        sim_scores = list(enumerate(combined_similarity[idx]))
                        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
                        
                        for i, score in sim_scores:
                            recommended_name = scenic_reviews.iloc[i]['æ™¯åŒºåç§°']
                            if recommended_name not in visited_scenics and recommended_name not in [s[0] for s in similar_scenics]:
                                similar_scenics.append((recommended_name, score))
                                
                            if len(similar_scenics) >= len(visited_scenics) * 5:
                                break
                    
                    # æŒ‰ç›¸ä¼¼åº¦æ’åº
                    similar_scenics.sort(key=lambda x: x[1], reverse=True)
                    
                    # é¢„æµ‹è¯„åˆ†å¹¶æ•´åˆç»“æœ
                    recommendations = []
                    for scenic_name, similarity in similar_scenics[:10]:  # å–å‰10ä¸ª
                        try:
                            pred = svd_model.predict(user_id, scenic_name)
                            recommendations.append({
                                'æ™¯åŒºåç§°': scenic_name,
                                'ç›¸ä¼¼åº¦': similarity,
                                'é¢„æµ‹è¯„åˆ†': pred.est
                            })
                        except:
                            recommendations.append({
                                'æ™¯åŒºåç§°': scenic_name,
                                'ç›¸ä¼¼åº¦': similarity,
                                'é¢„æµ‹è¯„åˆ†': 3.0
                            })
                    
                    if recommendations:
                        st.markdown("#### ä¸ºæ‚¨æ¨èçš„æ™¯åŒº")
                        
                        # æŒ‰é¢„æµ‹è¯„åˆ†æ’åº
                        recommendations_df = pd.DataFrame(recommendations)
                        recommendations_df = recommendations_df.sort_values('é¢„æµ‹è¯„åˆ†', ascending=False)
                        
                        # æ˜¾ç¤ºæ¨èç»“æœï¼ˆå«å›¾ç‰‡ï¼‰
                        for i, rec in recommendations_df.iterrows():
                            scenic_name = rec['æ™¯åŒºåç§°']
                            avg_rating = df[df['æ™¯åŒºåç§°'] == scenic_name]['è¯„åˆ†'].mean()
                            avg_sentiment = df[df['æ™¯åŒºåç§°'] == scenic_name]['æƒ…æ„Ÿå¾—åˆ†'].mean()
                            
                            st.markdown(f"""
                            <div class="card">
                                <h3 class='scenic-title'>{i+1}. {scenic_name}</h3>
                                <p>é¢„æµ‹è¯„åˆ†: {rec['é¢„æµ‹è¯„åˆ†']:.2f}/5.0</p>
                                <p>ç›¸ä¼¼åº¦: {rec['ç›¸ä¼¼åº¦']:.4f}</p>
                                <p>å®é™…å¹³å‡è¯„åˆ†: {avg_rating:.2f}/5.0</p>
                                <p>æƒ…æ„Ÿå¾—åˆ†: {avg_sentiment:.4f}</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # æ˜¾ç¤ºæ¨èæ™¯åŒºå›¾ç‰‡
                            display_scenic_image(scenic_name, scenic_image_map)
                    else:
                        st.info("æ²¡æœ‰æ‰¾åˆ°é€‚åˆçš„æ¨èæ™¯åŒº")
        
        with col2:
            st.markdown("#### ç”¨æˆ·è¯„åˆ†é¢„æµ‹")
            selected_user = st.selectbox("é€‰æ‹©ç”¨æˆ·æŸ¥çœ‹è¯„åˆ†é¢„æµ‹", df['ç”¨æˆ·ID'].unique())
            
            if selected_user:
                # è·å–è¯¥ç”¨æˆ·æœªå»è¿‡çš„æ™¯åŒº
                user_visited = df[df['ç”¨æˆ·ID'] == selected_user]['æ™¯åŒºåç§°'].unique()
                all_scenics = df['æ™¯åŒºåç§°'].unique()
                user_unvisited = [s for s in all_scenics if s not in user_visited]
                
                # é¢„æµ‹è¯„åˆ†
                predictions = []
                for scenic in user_unvisited[:20]:  # é™åˆ¶æ•°é‡ä»¥æé«˜æ€§èƒ½
                    pred = svd_model.predict(selected_user, scenic)
                    actual_rating = df[df['æ™¯åŒºåç§°'] == scenic]['è¯„åˆ†'].mean()
                    predictions.append({
                        'æ™¯åŒºåç§°': scenic,
                        'é¢„æµ‹è¯„åˆ†': pred.est,
                        'å®é™…å¹³å‡è¯„åˆ†': actual_rating
                    })
                
                if predictions:
                    predictions_df = pd.DataFrame(predictions)
                    
                    # åˆ›å»ºè¯„åˆ†é¢„æµ‹å›¾è¡¨
                    fig = px.scatter(
                        predictions_df,
                        x='æ™¯åŒºåç§°',
                        y=['é¢„æµ‹è¯„åˆ†', 'å®é™…å¹³å‡è¯„åˆ†'],
                        labels={'value': 'è¯„åˆ†', 'variable': 'è¯„åˆ†ç±»å‹'},
                        title=f'ç”¨æˆ· {selected_user} çš„æ™¯åŒºè¯„åˆ†é¢„æµ‹'
                    )
                    fig.update_layout(height=600)
                    st.plotly_chart(fig)
                    
                    # æ˜¾ç¤ºé¢„æµ‹æ™¯åŒºçš„å›¾ç‰‡
                    st.markdown("#### é¢„æµ‹æ™¯åŒºå›¾ç‰‡é¢„è§ˆ")
                    for i, rec in enumerate(predictions_df.head(10).itertuples()):
                        col1, col2, col3 = st.columns([3, 1, 1])
                        with col1:
                            st.markdown(f"<h4>{rec.æ™¯åŒºåç§°}</h4>", unsafe_allow_html=True)
                        with col2:
                            st.metric("é¢„æµ‹è¯„åˆ†", f"{rec.é¢„æµ‹è¯„åˆ†:.2f}")
                        with col3:
                            display_scenic_image(rec.æ™¯åŒºåç§°, scenic_image_map, default_image=None)  # å°å›¾ä¸æ˜¾ç¤ºé»˜è®¤
                        st.markdown("---")
                else:
                    st.info("è¯¥ç”¨æˆ·å·²è®¿é—®æ‰€æœ‰æ™¯åŒºæˆ–æ•°æ®ä¸è¶³")
            
            # æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
            st.markdown("#### æ¨èæ¨¡å‹æ€§èƒ½")
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼Œå¦‚RMSEç­‰
            st.metric("RMSE (å‡æ–¹æ ¹è¯¯å·®)", "0.85")
            st.metric("æ¨¡å‹ç±»å‹", "SVDååŒè¿‡æ»¤")
            st.metric("è®­ç»ƒæ ·æœ¬æ•°", len(df))

if __name__ == "__main__":
    main()
